# -*- coding: utf-8 -*-
"""NaiveBayes_Movie_Success_Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m4mqX31CR92RwgiF0_C5kWM0CI6MJw7A
"""

# INSE 6180 Security and Privacy Implications of Data Mining
# Group #17 Hit or Flop: Movie Success Prediction Using Data Mining Techniques
# Naive Bayes IMPLEMENTATION 2019 FALL

import cmath
import pandas as pd 
import numpy as np

#Data Loading
df=pd.read_csv('movies.csv')

# print(df)

#Data Cleaning
df1 = df.iloc[:,[0,8,12,18,19,20]]
# df1

#Data Partitioning
train = df1.sample(np.int(np.round(df1.shape[0]*0.8)), replace=True)
test = df1.sample(np.int(np.round(df1.shape[0]*0.2)), replace=True)
print("Training Data:\n",train)
print("\nTest Data:\n",test)

#vector creation
labelClass = train['Verdict']
sep_train = {}
for i in range(train.shape[0]):
		vector = train.iloc[i]
		class_value = vector[-1]
		if (class_value not in sep_train):
			sep_train[class_value] = list()
		sep_train[class_value].append(vector)

#find out mean and variance for each column of separated vector
tempC = sep_train['FLOP']
def meanC(columnD):
  return float(sum(columnD)/(float(len(columnD))))
def stdC(columnD):
  tempMean = meanC(columnD)
  tempSum = 0
  for i in range(0,len(columnD)):
    tempSum = tempSum + (columnD.iloc[i] - tempMean)*(columnD.iloc[i] - tempMean)
  return np.sqrt(tempSum/float(len(columnD)-1))

def parametersCalc(train,labelValue):
  meanRow = list()
  stdRow = list()
  tempData = train[train.Verdict == labelValue].iloc[:,:-1]
  for column in tempData:
    meanRow.append(meanC(tempData[column]))
    stdRow.append(stdC(tempData[column]))
  return meanRow,stdRow
print(parametersCalc(train, 'FLOP'))
print(parametersCalc(train, 'HIT'))

#Calculate probabilities and predict the results for the test data
def gaussianCalc(x,m,s):
	return (1 / (np.sqrt(2 * np.pi) * s)) * np.exp(-((x-m)**2 / (2 * s**2 )))
 
def predict (testData):
  '''
  Function which takes testData and outputs the predictions
  '''
  print(testData)
  meanRowF, stdRowF = parametersCalc(train,'FLOP')
  meanRowH, stdRowH = parametersCalc(train,'HIT')
  countTrue = 0
  countFalse = 0
  confusionMatrix =[[0,0], [0,0]]
  for j in range(0,testData.shape[0]):
    
    pF = 0
    pH = 0

    for i in range(0,testData.shape[1]-1):
      pF = pF + np.log(gaussianCalc(testData.iloc[j,i],meanRowF[i],stdRowF[i]))
      pH = pH + np.log(gaussianCalc(testData.iloc[j,i],meanRowH[i],stdRowH[i]))
    if (pF>pH and testData.iloc[j,-1] == 'FLOP'):
      #actual NO and predicted NO 0,0
      countTrue = countTrue + 1
      confusionMatrix[0][0] = confusionMatrix[0][0] + 1
    elif (pF<pH  and testData.iloc[j,-1] == 'HIT'):
      #actual YES and predicted YES 1,1
      countTrue = countTrue + 1
      confusionMatrix[1][1] = confusionMatrix[1][1] + 1
    elif (pF>pH  and testData.iloc[j,-1] == 'HIT'):
      #actual YES and predicted NO 1,0
      countFalse = countFalse + 1
      confusionMatrix[1][0] = confusionMatrix[1][0] + 1
    else:
      #actual NO and predicted YES 0,1
      countFalse = countFalse + 1
      confusionMatrix[0][1] = confusionMatrix[0][1] + 1
  accuracy = (countTrue/ (countFalse + countTrue))*100
  print ("\nAccuracy:", accuracy)
  print("\nConfusion Matrix:\n           Predicted_NO  Predicted_Yes\nActual_NO     ",confusionMatrix[0][0],"              ", confusionMatrix[0][1], "\nActual_Yes    ",confusionMatrix[1][0],"              ", confusionMatrix[1][1])
  print("\nTrue Positive:", confusionMatrix[1][1])
  print("False Positive:", confusionMatrix[0][1])
  print("True Negative:", confusionMatrix[0][0])
  print("False Negative:", confusionMatrix[1][0])
  precision = confusionMatrix[1][1] / (confusionMatrix[1][1] + confusionMatrix[0][1])  # = tp /tp+fp
  recall = confusionMatrix[1][1] / (confusionMatrix[1][1] + confusionMatrix[1][0]) # = tp /tp+fn
  fMeasure = 2*precision*recall/(precision+recall)
  print("\nPrecision: ",precision)
  print("Recall: ",recall)
  print("\nF-Measure: ",fMeasure)

predict(test)